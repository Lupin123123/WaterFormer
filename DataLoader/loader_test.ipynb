{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_train_list(orig_images_path, hazy_images_path):\n",
    "\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "\n",
    "    image_list_haze = glob.glob(os.path.join(hazy_images_path, \"*.png\"))\n",
    "    image_list_haze += glob.glob(os.path.join(hazy_images_path, \"*.jpg\"))\n",
    "    \n",
    "    ##############################################################\n",
    "\n",
    "    tmp_dict = {}\n",
    "    for image_path in image_list_haze:\n",
    "        key = image_path.split(\"\\\\\")[-1]\n",
    "        tmp_dict[key] = []\n",
    "        tmp_dict[key].append(image_path)\n",
    "    \n",
    "    ##############################################################\n",
    "\n",
    "    train_keys = []\n",
    "    len_keys = int(0.7*len(tmp_dict.keys()))\n",
    "    for i in range(len_keys):\n",
    "        train_keys.append(list(tmp_dict.keys())[i])\n",
    "\n",
    "    for key in list(tmp_dict.keys()):\n",
    "        if key in train_keys:\n",
    "            ori_path = os.path.join(orig_images_path, key)\n",
    "            hazy_path = os.path.join(orig_images_path, key)\n",
    "            # print(ori_path)\n",
    "            train_list.append((ori_path, hazy_path))\n",
    "        else:\n",
    "            val_list.append((os.path.join(orig_images_path, key), os.path.join(orig_images_path, key)))\n",
    "\n",
    "    random.shuffle(train_list)\n",
    "    random.shuffle(val_list)\n",
    "\n",
    "    return train_list, val_list\n",
    "\n",
    "\n",
    "class dehazing_loader(data.Dataset):\n",
    "    def __init__(self, orig_images_path, hazy_images_path, mode='train'):\n",
    "        self.train_list, self.val_list = populate_train_list(orig_images_path, hazy_images_path)\n",
    "        if mode == 'train':\n",
    "            self.data_list = self.train_list\n",
    "            print(\"Total training examples:\", len(self.train_list))\n",
    "        else:\n",
    "            self.data_list = self.val_list\n",
    "            print(\"Total validation examples:\", len(self.val_list))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_orig_path, data_hazy_path = self.data_list[index]\n",
    "\n",
    "        data_orig = Image.open(data_orig_path)\n",
    "        data_hazy = Image.open(data_hazy_path)\n",
    "\n",
    "        data_orig = data_orig.resize((480, 640), Image.ANTIALIAS)\n",
    "        data_hazy = data_hazy.resize((480, 640), Image.ANTIALIAS)\n",
    "\n",
    "        data_orig = (np.asarray(data_orig) / 255.0)\n",
    "        data_hazy = (np.asarray(data_hazy) / 255.0)\n",
    "\n",
    "        data_orig = torch.from_numpy(data_orig).float()\n",
    "        data_hazy = torch.from_numpy(data_hazy).float()\n",
    "\n",
    "        return data_orig.permute(2, 0, 1), data_hazy.permute(2, 0, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cautions\n",
    "若不在main中执行，num_workers要设置成0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "num_workers = 0\n",
    "ori_path = r'E:\\workspace\\work2\\UIEB\\train\\GT'\n",
    "hazy_path = r'E:\\workspace\\work2\\UIEB\\train\\hazy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dehazing_loader(\n",
    "                    orig_images_path=ori_path, \n",
    "                    hazy_images_path=hazy_path\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = dehazing_loader(\n",
    "                    orig_images_path=ori_path, \n",
    "                    hazy_images_path=hazy_path,\n",
    "                    mode='val'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size = train_batch_size,\n",
    "                shuffle = False,\n",
    "                num_workers = num_workers,\n",
    "                # pin_memory = True\n",
    "            )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "                val_dataset,\n",
    "                batch_size = val_batch_size,\n",
    "                shuffle = False,\n",
    "                num_workers = num_workers,\n",
    "                # pin_memory = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    print('epoch {}'.format(epoch))\n",
    "    for iteration, img_train in enumerate(train_loader):\n",
    "        # print(iteration)\n",
    "        img_ori, img_hazy = img_train\n",
    "        print('At {} train stage, ori_size:{}, hazy_size{}'.format(iteration, img_ori.shape, img_hazy.shape))\n",
    "        \n",
    "    for iteration, img_val in enumerate(val_loader):\n",
    "        img_ori, img_hazy = img_val\n",
    "        print('At {} val stage, ori_size:{}, hazy_size{}'.format(iteration, img_ori.shape, img_hazy.shape))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
